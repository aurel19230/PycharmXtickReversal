
# -*- coding: utf-8 -*-
"""optuna_bear_imbalance.py ‚Äì version 4
====================================
- Int√®gre **trois** conditions distinctes avec des plages de sampling diff√©rentes.
- Utilise **deux** datasets de validation pour une plus grande robustesse.
- Raccourci clavier ¬´ & ¬ª (utilisant pynput) pour d√©clencher un calcul imm√©diat
  sur le jeu TEST pendant l'optimisation.
- Affichage synth√©tique √† chaque trial + rapport d√©taill√© p√©riodique / sur
  nouveau meilleur score.
- Affichage color√© des r√©sultats avec colorama
- Ajout du nombre de sessions √† c√¥t√© du Total dans l'affichage des r√©sultats
- Ajout d'un affichage d√©taill√© des trades par cat√©gorie exclusive pour chaque dataset
- Adapt√© pour optimiser une strat√©gie bas√©e sur des imbalances baissi√®res en haut de bougie
"""
from __future__ import annotations

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ CONFIG ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
from pathlib import Path
import sys, time, math, optuna, pandas as pd, numpy as np
import threading

# Remplacer msvcrt par pynput
from pynput import keyboard

# Ajout de colorama pour les affichages color√©s
from colorama import init, Fore, Back, Style

# Initialiser colorama (n√©cessaire pour Windows)
init(autoreset=True)

RANDOM_SEED = 42
DIR = Path(r"C:/Users/aulac/OneDrive/Documents/Trading/VisualStudioProject/"
           r"Sierra chart/xTickReversal/simu/5_0_5TP_6SL/merge")

CSV_TRAIN = DIR / "Step5_5_0_5TP_6SL_010124_150525_extractOnlyFullSession_OnlyShort_feat__split1_01012024_01052024.csv"
CSV_TEST = DIR / "Step5_5_0_5TP_6SL_010124_150525_extractOnlyFullSession_OnlyShort_feat__split2_01052024_01102024.csv"
CSV_VAL1 = DIR / "Step5_5_0_5TP_6SL_010124_150525_extractOnlyFullSession_OnlyShort_feat__split3_01102024_28022025.csv"
CSV_VAL = DIR / "Step5_5_0_5TP_6SL_010124_150525_extractOnlyFullSession_OnlyShort_feat__split4_02032025_14052025.csv"

WINRATE_MIN = 0.52  # WR minimum acceptable
PCT_TRADE_MIN = 0.01  # % de candles trad√©es minimum
ALPHA = 0.70  # poids du WR dans le score
N_TRIALS = 10_000
PRINT_EVERY = 50
FAILED_PENALTY = -0.001

# Gap penalties
LAMBDA_WR = 0  # 0.60
LAMBDA_PCT = 0  # 0.20

# ‚îÄ‚îÄ Bornes par condition ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# Nouvelles bornes pour askVolHigh et bear_imbalance
ASK_MIN_1, ASK_MAX_1 = 1, 6  # Similaire aux bornes originales pour bid
BEAR_MIN_1, BEAR_MAX_1 = 2, 10  # Similaire aux bornes originales pour bull_imbalance

ASK_MIN_2, ASK_MAX_2 = 6, 25   # Chevauchement partiel avec Condition 1
BEAR_MIN_2, BEAR_MAX_2 = 2, 15  # Valeurs plus √©lev√©es, explor√©es diff√©remment

ASK_MIN_3, ASK_MAX_3 = 25, 90   # √âlargissement pour capturer plus de trades
BEAR_MIN_3, BEAR_MAX_3 = 1.5, 6 # √âlargissement pour am√©liorer la stabilit√©

import chardet


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ DATA LOADING ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def detect_file_encoding(file_path: str, sample_size: int = 100_000) -> str:
    with open(file_path, 'rb') as f:
        raw = f.read(sample_size)
    return chardet.detect(raw)['encoding']


def load_csv(path: str | Path) -> tuple[pd.DataFrame, int]:
    encoding = detect_file_encoding(str(path))
    if encoding.lower() == "ascii":
        encoding = "ISO-8859-1"

    print(f"{path.name} ‚ûú encodage d√©tect√©: {encoding}")

    # Chargement robuste
    df = pd.read_csv(path, sep=";", encoding=encoding, parse_dates=["date"], low_memory=False)

    # üîß Correction de SessionStartEnd
    df["SessionStartEnd"] = pd.to_numeric(df["SessionStartEnd"], errors="coerce")
    df = df.dropna(subset=["SessionStartEnd"])
    df["SessionStartEnd"] = df["SessionStartEnd"].astype(int)

    # üîç V√©rif des valeurs possibles
    print(f"{path.name} ‚ûú uniques SessionStartEnd: {df['SessionStartEnd'].unique()}")

    # üìä Compter les sessions avant filtre class_binaire
    nb_start = (df["SessionStartEnd"] == 10).sum()
    nb_end = (df["SessionStartEnd"] == 20).sum()
    nb_sessions = min(nb_start, nb_end)

    if nb_start != nb_end:
        print(
            f"{Fore.YELLOW}‚ö†Ô∏è Incoh√©rence sessions: {nb_start} d√©buts vs {nb_end} fins dans {path.name}{Style.RESET_ALL}")
    else:
        print(f"{Fore.GREEN}‚úî {nb_sessions} sessions compl√®tes d√©tect√©es dans {path.name}{Style.RESET_ALL}")

    # ‚úÖ Num√©rotation des sessions (avant filtrage)
    df["session_id"] = (df["SessionStartEnd"] == 10).cumsum().astype("int32")

    # üßº Seulement maintenant : filtrage de la cible
    df = df[df["class_binaire"].isin([0, 1])].copy()
    df.reset_index(drop=True, inplace=True)

    return df, nb_sessions


TRAIN, TRAIN_SESSIONS = load_csv(CSV_TRAIN)
VAL, VAL_SESSIONS = load_csv(CSV_VAL)
VAL1, VAL1_SESSIONS = load_csv(CSV_VAL1)
TEST, TEST_SESSIONS = load_csv(CSV_TEST)

# V√©rification de la coh√©rence des sessions (nombre de 10 == nombre de 20)
for name, df in zip(["TRAIN", "VAL", "VAL1", "TEST"], [TRAIN, VAL, VAL1, TEST]):
    start_sessions = df[df["SessionStartEnd"] == 10].shape[0]
    end_sessions = df[df["SessionStartEnd"] == 20].shape[0]
    if start_sessions != end_sessions:
        print(f"ATTENTION: {name} - Incoh√©rence dans les sessions: {start_sessions} d√©buts vs {end_sessions} fins")

# Affichage des informations sur les datasets
for lbl, d, sessions in zip(("TRAIN", "VAL", "VAL1", "TEST"),
                            (TRAIN, VAL, VAL1, TEST),
                            (TRAIN_SESSIONS, VAL_SESSIONS, VAL1_SESSIONS, TEST_SESSIONS)):
    print(f"{lbl:<5} | lignes={len(d):,}  WR brut={(d['class_binaire'] == 1).mean():.2%}  Sessions={sessions}")
print("‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n")


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ MASK BUILDERS ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def imbalance_high_rev(df: pd.DataFrame, *, askVolHigh: float, bear_imbalance_high_1: float, **kwargs) -> pd.Series:
    """Condition 1: Imbalance baissi√®re en haut de bougie"""
    return (df["askVolHigh"] > askVolHigh) & (df["bear_imbalance_high_1"] > bear_imbalance_high_1)


def imbalance_high_rev_2(df: pd.DataFrame, *, askVolHigh_2Cond: float, bear_imbalance_high_1_2Cond: float,
                         **kwargs) -> pd.Series:
    """Condition 2: Imbalance baissi√®re en haut de bougie avec param√®tres diff√©rents"""
    return (df["askVolHigh"] > askVolHigh_2Cond) & (df["bear_imbalance_high_1"] > bear_imbalance_high_1_2Cond)


def imbalance_high_rev_3(df: pd.DataFrame, *, askVolHigh_3Cond: float, bear_imbalance_high_1_3Cond: float,
                         **kwargs) -> pd.Series:
    """Condition 3: Imbalance baissi√®re en haut de bougie avec param√®tres encore diff√©rents"""
    return (df["askVolHigh"] > askVolHigh_3Cond) & (df["bear_imbalance_high_1"] > bear_imbalance_high_1_3Cond)


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ METRICS HELPERS ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def _metrics(df: pd.DataFrame, mask: pd.Series) -> tuple[float, float, int, int, int]:
    """Calcule les m√©triques avec le nombre de sessions couvertes"""
    sub = df.loc[mask]
    if sub.empty:
        return 0.0, 0.0, 0, 0, 0
    wins = int((sub["class_binaire"] == 1).sum())
    total = len(sub)
    # Calculer le nombre de sessions uniques o√π il y a des trades
    sessions_covered = sub["session_id"].nunique()
    return wins / total, total / len(df), wins, total - wins, sessions_covered


def _metrics_combined(df: pd.DataFrame, m1: pd.Series, m2: pd.Series, m3: pd.Series):
    """Calcule les m√©triques combin√©es avec le nombre de sessions couvertes"""
    m_u = m1 | m2 | m3
    m_12 = m1 & m2
    m_13 = m1 & m3
    m_23 = m2 & m3
    m_123 = m1 & m2 & m3
    return _metrics(df, m_u) + _metrics(df, m_12) + _metrics(df, m_13) + _metrics(df, m_23) + _metrics(df, m_123)


def _metrics_exclusive(df: pd.DataFrame, m1: pd.Series, m2: pd.Series, m3: pd.Series):
    """Calcule des m√©triques d√©taill√©es montrant les trades uniques et les chevauchements"""
    # Cat√©gories exclusives
    m1_only = m1 & ~m2 & ~m3  # Uniquement condition 1
    m2_only = ~m1 & m2 & ~m3  # Uniquement condition 2
    m3_only = ~m1 & ~m2 & m3  # Uniquement condition 3
    m12_only = m1 & m2 & ~m3  # Conditions 1 et 2 seulement
    m13_only = m1 & ~m2 & m3  # Conditions 1 et 3 seulement
    m23_only = ~m1 & m2 & m3  # Conditions 2 et 3 seulement
    m123 = m1 & m2 & m3  # Toutes les conditions

    # Global (union)
    m_u = m1 | m2 | m3

    # Calcul des m√©triques pour chaque cat√©gorie
    metrics_global = _metrics(df, m_u)
    metrics_1_only = _metrics(df, m1_only)
    metrics_2_only = _metrics(df, m2_only)
    metrics_3_only = _metrics(df, m3_only)
    metrics_12_only = _metrics(df, m12_only)
    metrics_13_only = _metrics(df, m13_only)
    metrics_23_only = _metrics(df, m23_only)
    metrics_123 = _metrics(df, m123)

    return {
        "global": metrics_global,
        "cond1_only": metrics_1_only,
        "cond2_only": metrics_2_only,
        "cond3_only": metrics_3_only,
        "cond12": metrics_12_only,
        "cond13": metrics_13_only,
        "cond23": metrics_23_only,
        "cond123": metrics_123
    }


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ OPTUNA OBJECTIVE ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# Initialisation de best_trial avec des valeurs par d√©faut
best_trial = {
    "score": -math.inf,
    "number": None,  # Initialisation de number √† None
    "score_old": -math.inf,
    # Autres champs initialis√©s √† des valeurs par d√©faut
    "wr_t": 0.0, "pct_t": 0.0, "suc_t": 0, "fail_t": 0, "sess_t": 0,
    "wr_v": 0.0, "pct_v": 0.0, "suc_v": 0, "fail_v": 0, "sess_v": 0,
    "wr_v1": 0.0, "pct_v1": 0.0, "suc_v1": 0, "fail_v1": 0, "sess_v1": 0,

    "wr_t1": 0.0, "pct_t1": 0.0, "suc_t1": 0, "fail_t1": 0, "sess_t1": 0,
    "wr_t2": 0.0, "pct_t2": 0.0, "suc_t2": 0, "fail_t2": 0, "sess_t2": 0,
    "wr_t3": 0.0, "pct_t3": 0.0, "suc_t3": 0, "fail_t3": 0, "sess_t3": 0,

    "wr_v1": 0.0, "pct_v1": 0.0, "suc_v1": 0, "fail_v1": 0, "sess_v1": 0,
    "wr_v2": 0.0, "pct_v2": 0.0, "suc_v2": 0, "fail_v2": 0, "sess_v2": 0,
    "wr_v3": 0.0, "pct_v3": 0.0, "suc_v3": 0, "fail_v3": 0, "sess_v3": 0,

    "wr_v1_1": 0.0, "pct_v1_1": 0.0, "suc_v1_1": 0, "fail_v1_1": 0, "sess_v1_1": 0,
    "wr_v1_2": 0.0, "pct_v1_2": 0.0, "suc_v1_2": 0, "fail_v1_2": 0, "sess_v1_2": 0,
    "wr_v1_3": 0.0, "pct_v1_3": 0.0, "suc_v1_3": 0, "fail_v1_3": 0, "sess_v1_3": 0,

    "avg_gap_wr": 0.0,
    "avg_gap_pct": 0.0,

    # Nouvelles m√©triques d√©taill√©es
    "metrics_detail_train": None,
    "metrics_detail_val": None,
    "metrics_detail_val1": None,

    "params": {}
}


def objective(trial: optuna.trial.Trial) -> float:
    # Param√®tres sp√©cifiques aux trois conditions
    p = {
        "askVolHigh": trial.suggest_int("askVolHigh", ASK_MIN_1, ASK_MAX_1),
        "bear_imbalance_high_1": trial.suggest_float("bear_imbalance_high_1", BEAR_MIN_1, BEAR_MAX_1),
        "askVolHigh_2Cond": trial.suggest_int("askVolHigh_2Cond", ASK_MIN_2, ASK_MAX_2),
        "bear_imbalance_high_1_2Cond": trial.suggest_float("bear_imbalance_high_1_2Cond", BEAR_MIN_2, BEAR_MAX_2),
        "askVolHigh_3Cond": trial.suggest_int("askVolHigh_3Cond", ASK_MIN_3, ASK_MAX_3),
        "bear_imbalance_high_1_3Cond": trial.suggest_float("bear_imbalance_high_1_3Cond", BEAR_MIN_3, BEAR_MAX_3),
    }

    # Masks pour le dataset TRAIN
    m1_t = imbalance_high_rev(TRAIN, **p)
    m2_t = imbalance_high_rev_2(TRAIN, **p)
    m3_t = imbalance_high_rev_3(TRAIN, **p)

    # Masks pour le premier dataset de validation VAL
    m1_v = imbalance_high_rev(VAL, **p)
    m2_v = imbalance_high_rev_2(VAL, **p)
    m3_v = imbalance_high_rev_3(VAL, **p)

    # Masks pour le second dataset de validation VAL1
    m1_v1 = imbalance_high_rev(VAL1, **p)
    m2_v1 = imbalance_high_rev_2(VAL1, **p)
    m3_v1 = imbalance_high_rev_3(VAL1, **p)

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ M√©triques TRAIN ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # M√©triques individuelles par condition avec sessions
    wr_t1, pct_t1, suc_t1, fail_t1, sess_t1 = _metrics(TRAIN, m1_t)
    wr_t2, pct_t2, suc_t2, fail_t2, sess_t2 = _metrics(TRAIN, m2_t)
    wr_t3, pct_t3, suc_t3, fail_t3, sess_t3 = _metrics(TRAIN, m3_t)

    # M√©trique combin√©e avec sessions
    wr_t, pct_t, suc_t, fail_t, sess_t, *_ = _metrics_combined(TRAIN, m1_t, m2_t, m3_t)

    # M√©triques d√©taill√©es par cat√©gorie
    metrics_detail_train = _metrics_exclusive(TRAIN, m1_t, m2_t, m3_t)

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ M√©triques VAL (Validation 1) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # M√©triques individuelles par condition avec sessions
    wr_v1, pct_v1, suc_v1, fail_v1, sess_v1 = _metrics(VAL, m1_v)
    wr_v2, pct_v2, suc_v2, fail_v2, sess_v2 = _metrics(VAL, m2_v)
    wr_v3, pct_v3, suc_v3, fail_v3, sess_v3 = _metrics(VAL, m3_v)

    # M√©trique combin√©e avec sessions
    wr_v, pct_v, suc_v, fail_v, sess_v, *_ = _metrics_combined(VAL, m1_v, m2_v, m3_v)

    # M√©triques d√©taill√©es par cat√©gorie
    metrics_detail_val = _metrics_exclusive(VAL, m1_v, m2_v, m3_v)

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ M√©triques VAL1 (Validation 2) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # M√©triques individuelles par condition avec sessions
    wr_v1_1, pct_v1_1, suc_v1_1, fail_v1_1, sess_v1_1 = _metrics(VAL1, m1_v1)
    wr_v1_2, pct_v1_2, suc_v1_2, fail_v1_2, sess_v1_2 = _metrics(VAL1, m2_v1)
    wr_v1_3, pct_v1_3, suc_v1_3, fail_v1_3, sess_v1_3 = _metrics(VAL1, m3_v1)

    # M√©trique combin√©e avec sessions
    wr_v1, pct_v1, suc_v1, fail_v1, sess_v1, *_ = _metrics_combined(VAL1, m1_v1, m2_v1, m3_v1)

    # M√©triques d√©taill√©es par cat√©gorie
    metrics_detail_val1 = _metrics_exclusive(VAL1, m1_v1, m2_v1, m3_v1)

    # Quick threshold veto - V√©rification des seuils sur les trois datasets
    if (wr_t < WINRATE_MIN or pct_t < PCT_TRADE_MIN or
            wr_v < WINRATE_MIN or pct_v < PCT_TRADE_MIN or
            wr_v1 < WINRATE_MIN or pct_v1 < PCT_TRADE_MIN):
        return FAILED_PENALTY

    # Calcul des √©carts entre les jeux de donn√©es
    gap_wr_tv = abs(wr_t - wr_v)
    gap_pct_tv = abs(pct_t - pct_v)

    gap_wr_tv1 = abs(wr_t - wr_v1)
    gap_pct_tv1 = abs(pct_t - pct_v1)

    gap_wr_vv1 = abs(wr_v - wr_v1)
    gap_pct_vv1 = abs(pct_v - pct_v1)

    # Moyenne des √©carts
    avg_gap_wr = (gap_wr_tv + gap_wr_tv1 + gap_wr_vv1) / 3
    avg_gap_pct = (gap_pct_tv + gap_pct_tv1 + gap_pct_vv1) / 3

    # Score qui consid√®re les trois datasets et les √©carts moyens
    score = (ALPHA * (wr_t + wr_v + wr_v1) / 3 +
             (1 - ALPHA) * (pct_t + pct_v + pct_v1) / 3 -
             LAMBDA_WR * avg_gap_wr -
             LAMBDA_PCT * avg_gap_pct)

    global best_trial
    if score > best_trial["score"]:
        best_trial = {
            "number": trial.number,
            "score": score,
            # M√©triques combin√©es - TRAIN
            "wr_t": wr_t, "pct_t": pct_t, "suc_t": suc_t, "fail_t": fail_t, "sess_t": sess_t,
            # M√©triques combin√©es - VAL
            "wr_v": wr_v, "pct_v": pct_v, "suc_v": suc_v, "fail_v": fail_v, "sess_v": sess_v,
            # M√©triques combin√©es - VAL1
            "wr_v1": wr_v1, "pct_v1": pct_v1, "suc_v1": suc_v1, "fail_v1": fail_v1, "sess_v1": sess_v1,

            # M√©triques par condition - TRAIN
            "wr_t1": wr_t1, "pct_t1": pct_t1, "suc_t1": suc_t1, "fail_t1": fail_t1, "sess_t1": sess_t1,
            "wr_t2": wr_t2, "pct_t2": pct_t2, "suc_t2": suc_t2, "fail_t2": fail_t2, "sess_t2": sess_t2,
            "wr_t3": wr_t3, "pct_t3": pct_t3, "suc_t3": suc_t3, "fail_t3": fail_t3, "sess_t3": sess_t3,

            # M√©triques par condition - VAL
            "wr_v1": wr_v1, "pct_v1": pct_v1, "suc_v1": suc_v1, "fail_v1": fail_v1, "sess_v1": sess_v1,
            "wr_v2": wr_v2, "pct_v2": pct_v2, "suc_v2": suc_v2, "fail_v2": fail_v2, "sess_v2": sess_v2,
            "wr_v3": wr_v3, "pct_v3": pct_v3, "suc_v3": suc_v3, "fail_v3": fail_v3, "sess_v3": sess_v3,

            # M√©triques par condition - VAL1
            "wr_v1_1": wr_v1_1, "pct_v1_1": pct_v1_1, "suc_v1_1": suc_v1_1, "fail_v1_1": fail_v1_1,
            "sess_v1_1": sess_v1_1,
            "wr_v1_2": wr_v1_2, "pct_v1_2": pct_v1_2, "suc_v1_2": suc_v1_2, "fail_v1_2": fail_v1_2,
            "sess_v1_2": sess_v1_2,
            "wr_v1_3": wr_v1_3, "pct_v1_3": pct_v1_3, "suc_v1_3": suc_v1_3, "fail_v1_3": fail_v1_3,
            "sess_v1_3": sess_v1_3,

            # √âcarts moyens
            "avg_gap_wr": avg_gap_wr,
            "avg_gap_pct": avg_gap_pct,

            # M√©triques d√©taill√©es
            "metrics_detail_train": metrics_detail_train,
            "metrics_detail_val": metrics_detail_val,
            "metrics_detail_val1": metrics_detail_val1,

            "params": p
        }

    # Live print avec les trois datasets
    print(f"{trial.number:>6} | "
          f"TR {Fore.GREEN}{wr_t:6.2%}{Style.RESET_ALL}/{pct_t:6.2%} | "
          f"V1 {Fore.GREEN}{wr_v:6.2%}{Style.RESET_ALL}/{pct_v:6.2%} | "
          f"V2 {Fore.GREEN}{wr_v1:6.2%}{Style.RESET_ALL}/{pct_v1:6.2%}",
          f"{Fore.GREEN}‚úî{Style.RESET_ALL}" if score > best_trial.get("score_old", -math.inf) else "")

    best_trial["score_old"] = score  # helper for symbol
    return score


# Fonction pour afficher les m√©triques d√©taill√©es
def print_detailed_metrics(dataset_name, metrics_detail):
    """Affiche les m√©triques d√©taill√©es par cat√©gorie de trades"""

    wr_g, pct_g, suc_g, fail_g, sess_g = metrics_detail["global"]
    wr_1, pct_1, suc_1, fail_1, sess_1 = metrics_detail["cond1_only"]
    wr_2, pct_2, suc_2, fail_2, sess_2 = metrics_detail["cond2_only"]
    wr_3, pct_3, suc_3, fail_3, sess_3 = metrics_detail["cond3_only"]
    wr_12, pct_12, suc_12, fail_12, sess_12 = metrics_detail["cond12"]
    wr_13, pct_13, suc_13, fail_13, sess_13 = metrics_detail["cond13"]
    wr_23, pct_23, suc_23, fail_23, sess_23 = metrics_detail["cond23"]
    wr_123, pct_123, suc_123, fail_123, sess_123 = metrics_detail["cond123"]

    # Calculer les totaux pour chaque cat√©gorie
    total_g = suc_g + fail_g
    total_1 = suc_1 + fail_1
    total_2 = suc_2 + fail_2
    total_3 = suc_3 + fail_3
    total_12 = suc_12 + fail_12
    total_13 = suc_13 + fail_13
    total_23 = suc_23 + fail_23
    total_123 = suc_123 + fail_123

    # V√©rification de la somme
    total_details = total_1 + total_2 + total_3 + total_12 + total_13 + total_23 + total_123

    print(f"\n    {Fore.CYAN}[D√âTAIL PAR CAT√âGORIE DE TRADES - {dataset_name}]{Style.RESET_ALL}")
    print(f"    Condition 1 uniquement : WR={Fore.GREEN}{wr_1:.2%}{Style.RESET_ALL} | "
          f"Total={Fore.CYAN}{total_1}{Style.RESET_ALL}")
    print(f"    Condition 2 uniquement : WR={Fore.GREEN}{wr_2:.2%}{Style.RESET_ALL} | "
          f"Total={Fore.CYAN}{total_2}{Style.RESET_ALL}")
    print(f"    Condition 3 uniquement : WR={Fore.GREEN}{wr_3:.2%}{Style.RESET_ALL} | "
          f"Total={Fore.CYAN}{total_3}{Style.RESET_ALL}")
    print(f"    Conditions 1+2 : WR={Fore.GREEN}{wr_12:.2%}{Style.RESET_ALL} | "
          f"Total={Fore.CYAN}{total_12}{Style.RESET_ALL}")
    print(f"    Conditions 1+3 : WR={Fore.GREEN}{wr_13:.2%}{Style.RESET_ALL} | "
          f"Total={Fore.CYAN}{total_13}{Style.RESET_ALL}")
    print(f"    Conditions 2+3 : WR={Fore.GREEN}{wr_23:.2%}{Style.RESET_ALL} | "
          f"Total={Fore.CYAN}{total_23}{Style.RESET_ALL}")
    print(f"    Toutes conditions (1+2+3) : WR={Fore.GREEN}{wr_123:.2%}{Style.RESET_ALL} | "
          f"Total={Fore.CYAN}{total_123}{Style.RESET_ALL}")

    # V√©rification
    print(
        f"    {Fore.YELLOW}V√©rification : {total_details} trades cat√©goris√©s vs {total_g} total global{Style.RESET_ALL}")
    if total_details != total_g:
        print(f"    {Fore.RED}‚ö†Ô∏è Anomalie d√©tect√©e: La somme des d√©tails ({total_details}) "
              f"ne correspond pas au total global ({total_g}){Style.RESET_ALL}")


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ HOLD‚ÄëOUT TEST ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def calculate_test_metrics(params: dict):
    print(f"\n{Fore.CYAN}üßÆ  Calcul sur DATASET TEST{Style.RESET_ALL}\n")
    m1 = imbalance_high_rev(TEST, **params)
    m2 = imbalance_high_rev_2(TEST, **params)
    m3 = imbalance_high_rev_3(TEST, **params)

    # Calcul des m√©triques par condition avec sessions
    wr_1, pct_1, suc_1, fail_1, sess_1 = _metrics(TEST, m1)
    wr_2, pct_2, suc_2, fail_2, sess_2 = _metrics(TEST, m2)
    wr_3, pct_3, suc_3, fail_3, sess_3 = _metrics(TEST, m3)

    # Calcul des m√©triques combin√©es avec sessions
    wr_u, pct_u, suc_u, fail_u, sess_u, *_ = _metrics_combined(TEST, m1, m2, m3)

    # Calcul des m√©triques d√©taill√©es par cat√©gorie
    metrics_detail_test = _metrics_exclusive(TEST, m1, m2, m3)

    # Affichage d√©taill√© par condition
    print(f"{Fore.YELLOW}--- D√©tail par condition ---{Style.RESET_ALL}")
    print(f"Condition 1: WR={Fore.GREEN}{wr_1:.2%}{Style.RESET_ALL}  pct={pct_1:.2%}  "
          f"‚úì{Fore.GREEN}{suc_1}{Style.RESET_ALL} ‚úó{Fore.RED}{fail_1}{Style.RESET_ALL}  "
          f"Total={Fore.CYAN}{suc_1 + fail_1}{Style.RESET_ALL} (sessions: {TEST_SESSIONS})")
    print(f"Condition 2: WR={Fore.GREEN}{wr_2:.2%}{Style.RESET_ALL}  pct={pct_2:.2%}  "
          f"‚úì{Fore.GREEN}{suc_2}{Style.RESET_ALL} ‚úó{Fore.RED}{fail_2}{Style.RESET_ALL}  "
          f"Total={Fore.CYAN}{suc_2 + fail_2}{Style.RESET_ALL} (sessions: {TEST_SESSIONS})")
    print(f"Condition 3: WR={Fore.GREEN}{wr_3:.2%}{Style.RESET_ALL}  pct={pct_3:.2%}  "
          f"‚úì{Fore.GREEN}{suc_3}{Style.RESET_ALL} ‚úó{Fore.RED}{fail_3}{Style.RESET_ALL}  "
          f"Total={Fore.CYAN}{suc_3 + fail_3}{Style.RESET_ALL} (sessions: {TEST_SESSIONS})")

    # Affichage r√©sultat combin√©
    print(f"\n{Fore.YELLOW}--- R√©sultat combin√© (union) ---{Style.RESET_ALL}")
    print(f"Union: WR={Fore.GREEN}{wr_u:.2%}{Style.RESET_ALL}  pct={pct_u:.2%}  "
          f"‚úì{Fore.GREEN}{suc_u}{Style.RESET_ALL} ‚úó{Fore.RED}{fail_u}{Style.RESET_ALL}  "
          f"Total={Fore.CYAN}{suc_u + fail_u}{Style.RESET_ALL} (sessions: {TEST_SESSIONS})")

    # Affichage d√©taill√© par cat√©gorie de trades
    print_detailed_metrics("TEST", metrics_detail_test)

    is_valid = (wr_u >= WINRATE_MIN and pct_u >= PCT_TRADE_MIN)
    if is_valid:
        print(f"{Fore.GREEN}‚úÖ VALIDE{Style.RESET_ALL}\n\n")
    else:
        print(f"{Fore.RED}‚ùå REJET{Style.RESET_ALL}")

    return wr_u, pct_u, suc_u, fail_u, sess_u


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ KEYBOARD LISTENING ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
RUN_TEST = False


def on_press(key):
    global RUN_TEST
    try:
        if key.char == '&':
            print(f"\n{Fore.YELLOW}üß™  Test demand√© via '&'{Style.RESET_ALL}")
            RUN_TEST = True
    except AttributeError:
        # Touche sp√©ciale sans caract√®re
        pass


# D√©marrer listener dans un thread s√©par√©
def start_keyboard_listener():
    listener = keyboard.Listener(on_press=on_press)
    listener.daemon = True  # Le thread sera automatiquement termin√© quand le programme principal se termine
    listener.start()
    return listener


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ MAIN LOOP ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def main() -> None:
    optuna.logging.set_verbosity(optuna.logging.WARNING)
    study = optuna.create_study(direction="maximize",
                                sampler=optuna.samplers.TPESampler(seed=RANDOM_SEED))
    last_best_shown = None

    # D√©marrer le listener clavier
    listener = start_keyboard_listener()
    print(
        f"{Fore.CYAN}√âcouteur clavier d√©marr√© - appuyez sur '&' √† tout moment pour tester sur le dataset TEST{Style.RESET_ALL}")

    for done in range(1, N_TRIALS + 1):
        study.optimize(objective, n_trials=1)

        if RUN_TEST:
            globals()["RUN_TEST"] = False
            calculate_test_metrics(study.best_params)

        if best_trial.get("number") is not None:
            print(f"Best trial {best_trial['number']}  value {Fore.GREEN}{best_trial['score']:.4f}{Style.RESET_ALL}",
                  end="\r")

        if (done % PRINT_EVERY == 0 or best_trial.get("number") != last_best_shown):
            bt = best_trial
            print(
                f"\n\n{Fore.YELLOW}*** BEST so far ‚ñ∏ trial {bt['number']}  score={Fore.GREEN}{bt['score']:.4f}{Style.RESET_ALL}")

            # Affichage global avec trades r√©ussis/√©chou√©s/totaux et sessions
            print(f"    {Fore.CYAN}[GLOBAL - Trades uniques]{Style.RESET_ALL}")
            print(f"    TR WR {Fore.GREEN}{bt['wr_t']:.2%}{Style.RESET_ALL} | "
                  f"pct {bt['pct_t']:.2%} | "
                  f"‚úì{Fore.GREEN}{bt['suc_t']}{Style.RESET_ALL} "
                  f"‚úó{Fore.RED}{bt['fail_t']}{Style.RESET_ALL} "
                  f"Total={Fore.CYAN}{bt['suc_t'] + bt['fail_t']}{Style.RESET_ALL} (sessions: {TRAIN_SESSIONS})")

            print(f"    V1 WR {Fore.GREEN}{bt['wr_v']:.2%}{Style.RESET_ALL} | "
                  f"pct {bt['pct_v']:.2%} | "
                  f"‚úì{Fore.GREEN}{bt['suc_v']}{Style.RESET_ALL} "
                  f"‚úó{Fore.RED}{bt['fail_v']}{Style.RESET_ALL} "
                  f"Total={Fore.CYAN}{bt['suc_v'] + bt['fail_v']}{Style.RESET_ALL} (sessions: {VAL_SESSIONS})")

            print(f"    V2 WR {Fore.GREEN}{bt['wr_v1']:.2%}{Style.RESET_ALL} | "
                  f"pct {bt['pct_v1']:.2%} | "
                  f"‚úì{Fore.GREEN}{bt['suc_v1']}{Style.RESET_ALL} "
                  f"‚úó{Fore.RED}{bt['fail_v1']}{Style.RESET_ALL} "
                  f"Total={Fore.CYAN}{bt['suc_v1'] + bt['fail_v1']}{Style.RESET_ALL} (sessions: {VAL1_SESSIONS})")

            # Affichage des √©carts moyens
            print(f"    Gap WR moyen: {Fore.YELLOW}{bt['avg_gap_wr']:.2%}{Style.RESET_ALL} | "
                  f"Gap PCT moyen: {Fore.YELLOW}{bt['avg_gap_pct']:.2%}{Style.RESET_ALL}")

            # Affichage d√©taill√© par cat√©gorie de trades pour chaque dataset
            if bt['metrics_detail_train']:
                print_detailed_metrics("TRAIN", bt['metrics_detail_train'])

            if bt['metrics_detail_val']:
                print_detailed_metrics("VAL", bt['metrics_detail_val'])

            if bt['metrics_detail_val1']:
                print_detailed_metrics("VAL1", bt['metrics_detail_val1'])

            # D√©tail par condition (affichage original)
            print(f"\n    {Fore.CYAN}[Condition 1]{Style.RESET_ALL}")
            print(f"    TR WR {Fore.GREEN}{bt['wr_t1']:.2%}{Style.RESET_ALL} | "
                  f"pct {bt['pct_t1']:.2%} | "
                  f"‚úì{Fore.GREEN}{bt['suc_t1']}{Style.RESET_ALL} "
                  f"‚úó{Fore.RED}{bt['fail_t1']}{Style.RESET_ALL} "
                  f"Total={Fore.CYAN}{bt['suc_t1'] + bt['fail_t1']}{Style.RESET_ALL} (sessions: {TRAIN_SESSIONS})")

            print(f"    V1 WR {Fore.GREEN}{bt['wr_v1']:.2%}{Style.RESET_ALL} | "
                  f"pct {bt['pct_v1']:.2%} | "
                  f"‚úì{Fore.GREEN}{bt['suc_v1']}{Style.RESET_ALL} "
                  f"‚úó{Fore.RED}{bt['fail_v1']}{Style.RESET_ALL} "
                  f"Total={Fore.CYAN}{bt['suc_v1'] + bt['fail_v1']}{Style.RESET_ALL} (sessions: {VAL_SESSIONS})")

            print(f"    V2 WR {Fore.GREEN}{bt['wr_v1_1']:.2%}{Style.RESET_ALL} | "
                  f"pct {bt['pct_v1_1']:.2%} | "
                  f"‚úì{Fore.GREEN}{bt['suc_v1_1']}{Style.RESET_ALL} "
                  f"‚úó{Fore.RED}{bt['fail_v1_1']}{Style.RESET_ALL} "
                  f"Total={Fore.CYAN}{bt['suc_v1_1'] + bt['fail_v1_1']}{Style.RESET_ALL} (sessions: {VAL1_SESSIONS})")

            print(f"\n    {Fore.CYAN}[Condition 2]{Style.RESET_ALL}")
            print(f"    TR WR {Fore.GREEN}{bt['wr_t2']:.2%}{Style.RESET_ALL} | "
                  f"pct {bt['pct_t2']:.2%} | "
                  f"‚úì{Fore.GREEN}{bt['suc_t2']}{Style.RESET_ALL} "
                  f"‚úó{Fore.RED}{bt['fail_t2']}{Style.RESET_ALL} "
                  f"Total={Fore.CYAN}{bt['suc_t2'] + bt['fail_t2']}{Style.RESET_ALL} (sessions: {TRAIN_SESSIONS})")

            print(f"    V1 WR {Fore.GREEN}{bt['wr_v2']:.2%}{Style.RESET_ALL} | "
                  f"pct {bt['pct_v2']:.2%} | "
                  f"‚úì{Fore.GREEN}{bt['suc_v2']}{Style.RESET_ALL} "
                  f"‚úó{Fore.RED}{bt['fail_v2']}{Style.RESET_ALL} "
                  f"Total={Fore.CYAN}{bt['suc_v2'] + bt['fail_v2']}{Style.RESET_ALL} (sessions: {VAL_SESSIONS})")

            print(f"    V2 WR {Fore.GREEN}{bt['wr_v1_2']:.2%}{Style.RESET_ALL} | "
                  f"pct {bt['pct_v1_2']:.2%} | "
                  f"‚úì{Fore.GREEN}{bt['suc_v1_2']}{Style.RESET_ALL} "
                  f"‚úó{Fore.RED}{bt['fail_v1_2']}{Style.RESET_ALL} "
                  f"Total={Fore.CYAN}{bt['suc_v1_2'] + bt['fail_v1_2']}{Style.RESET_ALL} (sessions: {VAL1_SESSIONS})")

            print(f"\n    {Fore.CYAN}[Condition 3]{Style.RESET_ALL}")
            print(f"    TR WR {Fore.GREEN}{bt['wr_t3']:.2%}{Style.RESET_ALL} | "
                  f"pct {bt['pct_t3']:.2%} | "
                  f"‚úì{Fore.GREEN}{bt['suc_t3']}{Style.RESET_ALL} "
                  f"‚úó{Fore.RED}{bt['fail_t3']}{Style.RESET_ALL} "
                  f"Total={Fore.CYAN}{bt['suc_t3'] + bt['fail_t3']}{Style.RESET_ALL} (sessions: {TRAIN_SESSIONS})")

            print(f"    V1 WR {Fore.GREEN}{bt['wr_v3']:.2%}{Style.RESET_ALL} | "
                  f"pct {bt['pct_v3']:.2%} | "
                  f"‚úì{Fore.GREEN}{bt['suc_v3']}{Style.RESET_ALL} "
                  f"‚úó{Fore.RED}{bt['fail_v3']}{Style.RESET_ALL} "
                  f"Total={Fore.CYAN}{bt['suc_v3'] + bt['fail_v3']}{Style.RESET_ALL} (sessions: {VAL_SESSIONS})")

            print(f"    V2 WR {Fore.GREEN}{bt['wr_v1_3']:.2%}{Style.RESET_ALL} | "
                  f"pct {bt['pct_v1_3']:.2%} | "
                  f"‚úì{Fore.GREEN}{bt['suc_v1_3']}{Style.RESET_ALL} "
                  f"‚úó{Fore.RED}{bt['fail_v1_3']}{Style.RESET_ALL} "
                  f"Total={Fore.CYAN}{bt['suc_v1_3'] + bt['fail_v1_3']}{Style.RESET_ALL} (sessions: {VAL1_SESSIONS})")

            print(f"\n    params ‚ûú {Fore.MAGENTA}{bt['params']}{Style.RESET_ALL}\n")

            last_best_shown = best_trial["number"]

    # Ces deux lignes doivent √™tre align√©es avec la d√©finition de la boucle for,
    # pas avec le contenu de la boucle
    print(f"\n{Fore.YELLOW}üîö  Fin des essais Optuna.{Style.RESET_ALL}")
    calculate_test_metrics(study.best_params)


if __name__ == "__main__":
    main()
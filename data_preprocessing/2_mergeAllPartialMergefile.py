"""
Fusionne les fichiers Step1_*_X.csv placÃ©s dans le dossier ...\merge
  â€¢ ConcatÃ¨ne dans lâ€™ordre _0, _1, _2 â€¦         (obligatoire & consÃ©cutif)
  â€¢ Option â€˜dâ€™ : dÃ©-doublonne selon un groupe de colonnes et
                 conserve le plus petit timeStampOpening
  â€¢ VÃ©rifie quâ€™Ã  lâ€™issue la colonne timeStampOpening est
    STRICTEMENT croissante ; sinon, affiche les paires fautives
    puis lÃ¨ve ValueError.

Sortie : Step2_<config>_<startDate>_<endDate>.csv (sÃ©parateur â€˜;â€™)
------------------------------------------------------------------------
Â© 2025 â€“ script destinÃ© Ã  un usage interne
"""

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Imports â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import os
import re
import numpy as np
import pandas as pd

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ParamÃ©trage dossier â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
directory = (
    r"C:\Users\aulac\OneDrive\Documents\Trading\VisualStudioProject"
    r"\Sierra chart\xTickReversal\simu\5_0_5TP_6SL\merge"
)

# Extraire le nom de config (rÃ©pertoire parent de Â« merge Â»)
path_components   = directory.split(os.sep)
merge_index       = path_components.index("merge")
xtickRev_config_dir = path_components[merge_index - 1]

print(f"Configuration dÃ©tectÃ©e : {xtickRev_config_dir}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Choice de lâ€™utilisateur â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
option = input(
    "Appuyez sur 'd' pour dÃ©-doublonner, EntrÃ©e pour concatÃ©ner simplement : "
).lower()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Function : anomalies chronologiques â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def show_timestamp_anomalies(timestamps: np.ndarray, label: str = "timeStampOpening"):
    """Affiche les inversions strictes t[i] > t[i+1] et lÃ¨ve ValueError."""
    bad_idx = np.where(np.diff(timestamps) < 0)[0]
    if bad_idx.size == 0:
        print(f"âœ”ï¸  Aucun problÃ¨me dâ€™ordre chronologique dÃ©tectÃ© dans Â« {label} Â» "
              f"({len(timestamps)} valeurs).")
        return
    print(f"\nâŒ  {bad_idx.size} inversion(s) dÃ©tectÃ©e(s) dans Â« {label} Â» :")
    for i in bad_idx:
        print(f"  â€¢ ligne {i+1:>8} : {int(timestamps[i])}  â†’  ligne {i+2:>8} : "
              f"{int(timestamps[i+1])}")
    print("\nArrÃªt du traitement car lâ€™ordre nâ€™est pas strictement croissant.")
    raise ValueError("Impossible dâ€™obtenir un ordre chronologique strict des timeStampOpening.")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Function : nom de fichier de sortie â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def generate_output_filename(files, config_dir):
    if not files:
        raise ValueError("La liste des fichiers est vide.")
    sorted_files = sorted(files)
    first_file   = next((f for f in sorted_files if f.endswith("_0.csv")), None)
    if first_file is None:
        raise ValueError("Aucun fichier ne se termine par '_0.csv'.")
    start_date   = first_file.split("_")[1]
    last_file    = max(sorted_files,
                       key=lambda x: int(x.split("_")[-1].split(".")[0]))
    end_date     = last_file.split("_")[2]
    return f"Step2_{config_dir}_{start_date}_{end_date}.csv"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Function : merge files â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def merge_files(directory_path: str) -> pd.DataFrame:
    # Liste et tri des fichiers *_X.csv
    all_csv   = [f for f in os.listdir(directory_path) if f.endswith(".csv")]
    files     = [f for f in all_csv if re.match(r".+_\d+\.csv$", f)]
    files.sort(key=lambda f: int(re.findall(r"_(\d+)\.csv$", f)[0]))

    print("Fichiers Ã  fusionner :")
    for f in files:
        print(f" - {f}")
    print()
    if not files:
        raise ValueError("Aucun fichier *_X.csv trouvÃ© dans le dossier.")

    file_numbers = [int(re.findall(r"_(\d+)\.csv$", f)[0]) for f in files]
    if file_numbers != list(range(len(file_numbers))):
        raise ValueError("Les fichiers ne sont pas consÃ©cutifs ou ne commencent pas par *_0.csv.")

    # Lecture sÃ©quentielle
    dfs = []
    for idx, file in enumerate(files):
        fp = os.path.join(directory_path, file)
        df = pd.read_csv(fp, delimiter=";", header=0)
        print(f"Traitement du fichier {file} : {len(df)} lignes")
        dfs.append(df)

    merged_df = pd.concat(dfs, ignore_index=True)

    # ------------------- Option de dÃ©-doublonnage ----------------------------
    if option == "d":
        print("\nðŸ§¹  DÃ©-doublonnage activÃ©")
        merged_df["timeStampOpening"] = pd.to_numeric(merged_df["timeStampOpening"])
        cols_check = [
            "close", "open", "high", "low", "volume",
            "atr", "vaDelta_6periods", "vaVol_16periods"
        ]
        # Analyse prÃ©-suppression
        duplicates = merged_df[merged_df.duplicated(subset=cols_check, keep=False)].copy()
        if not duplicates.empty:
            for keys, grp in duplicates.groupby(cols_check):
                n_del = len(grp) - 1
                keep_ts = grp["timeStampOpening"].min()
                print("\nGroupe de doublons:")
                print(f"Nombre de lignes Ã  supprimer : {n_del}")
                print(f"timeStampOpening conservÃ©    : {keep_ts}")
                print(grp.sort_values("timeStampOpening"))
                print("-" * 80)

        merged_df = (merged_df
                     .sort_values("timeStampOpening")
                     .drop_duplicates(subset=cols_check, keep="first")
                     .reset_index(drop=True))

        print("\nDÃ©-doublonnage terminÃ©.")
        print(f"Lignes aprÃ¨s nettoyage : {len(merged_df)}")

    # -------------------- VÃ©rification chronologique -------------------------
    if not merged_df["timeStampOpening"].is_monotonic_increasing:
        show_timestamp_anomalies(
            merged_df["timeStampOpening"].to_numpy(dtype=np.int64),
            label="timeStampOpening"
        )  # lÃ¨ve dÃ©jÃ  ValueError
    else:
        print("Les timeStampOpening sont strictement croissants.")

    print(f"\nNombre total de lignes aprÃ¨s fusion : {len(merged_df)}")
    return merged_df

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ExÃ©cution principale â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
try:
    merged = merge_files(directory)

    files_for_name = [f for f in os.listdir(directory) if re.match(r".+_\d+\.csv$", f)]
    output_name    = generate_output_filename(files_for_name, xtickRev_config_dir)
    output_path    = os.path.join(directory, output_name)

    merged.to_csv(output_path, index=False, sep=";")
    print(f"\nâœ…  Fusion terminÃ©e. RÃ©sultat sauvegardÃ© : {output_path}")

except ValueError as err:
    print(f"\nErreur : {err}")

except Exception as exc:
    print(f"\nUne erreur inattendue sâ€™est produite : {exc}")

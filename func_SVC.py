
from definition import *

def train_and_evaluate_svc_model(
        X_train_cv=None,
        X_val_cv=None,
        y_train_cv=None,
        y_val_cv=None,
        y_pnl_data_train_cv=None,
        y_pnl_data_val_cv_OrTest=None,
        params_optuna=None,
        model_weight_optuna=None,
        config=None,
        fold_num=0,
        fold_stats_current=None,
        train_pos=None,
        val_pos=None,
        log_evaluation=0,
):
    from sklearn.svm import SVC
    import numpy as np
    import time
    from sklearn.metrics import brier_score_loss

    # Mesure du temps total de la fonction
    start_time_total = time.time()

    # Calcul des poids
    start_time_weights = time.time()
    sample_weights_train, sample_weights_val = compute_sample_weights(y_train_cv, y_val_cv)
    weights_time = time.time() - start_time_weights
    #print(f"Temps de calcul des poids: {weights_time:.4f} secondes")

    # Assurer que les param√®tres par d√©faut sont d√©finis
    if params_optuna is None:
        raise ValueError(
            "params_optuna ne peut pas √™tre None. Veuillez fournir un dictionnaire de param√®tres pour le mod√®le SVC.")

    # # R√©cup√©rer l'option de probabilit√© depuis la configuration
    # svc_probability = config.get('svc_probability', False)
    # params_optuna['probability'] = svc_probability
    #
    # # R√©cup√©rer le type de noyau depuis la configuration
    # svc_kernel = config.get('svc_kernel', 'rbf')
    # params_optuna['kernel'] = svc_kernel

    #print(params_optuna)
    # Mesure du temps d'entra√Ænement
    start_time_train = time.time()
    # Entra√Ænement du mod√®le SVC
    current_model = SVC(**params_optuna)
    current_model.fit(X_train_cv, y_train_cv, sample_weight=sample_weights_train)
    train_time = time.time() - start_time_train
    print(f"Temps d'entra√Ænement du mod√®le: {train_time:.4f} secondes")

    # Pr√©dictions et m√©triques pour la validation
    start_time_val_pred = time.time()
    svc_probability=config['svc_probability']
    # Selon l'option de probabilit√©, r√©cup√©rer les pr√©dictions diff√©remment
    if svc_probability:
        val_pred_proba = current_model.predict_proba(X_val_cv)[:, 1]
        threshold = model_weight_optuna.get('threshold', 0.5)
        val_pred = (val_pred_proba >= threshold).astype(int)
        val_pred_proba_log_odds = np.log(val_pred_proba / (1 - val_pred_proba + 1e-10))
    else:
        val_pred = current_model.predict(X_val_cv)
        # Utiliser la distance √† l'hyperplan (decision_function) comme proxy pour la probabilit√©
        decision_values = current_model.decision_function(X_val_cv)
        # Normaliser les valeurs de d√©cision pour une approximation de probabilit√©
        val_pred_proba = 1 / (1 + np.exp(-decision_values))
        val_pred_proba_log_odds = decision_values

    val_pred_time = time.time() - start_time_val_pred
    #print(f"Temps de pr√©diction sur validation: {val_pred_time:.4f} secondes")

    # Calcul des m√©triques pour la validation
    start_time_val_metrics = time.time()
    from sklearn.metrics import confusion_matrix
    tn_val, fp_val, fn_val, tp_val = confusion_matrix(y_val_cv, val_pred).ravel()
    val_metrics_time = time.time() - start_time_val_metrics
    #print(f"Temps de calcul des m√©triques de validation: {val_metrics_time:.4f} secondes")

    # Mesure du temps pour les pr√©dictions sur l'ensemble d'entra√Ænement
    start_time_train_pred = time.time()

    # Selon l'option de probabilit√©, r√©cup√©rer les pr√©dictions diff√©remment
    if svc_probability:
        y_train_predProba = current_model.predict_proba(X_train_cv)[:, 1]
        threshold = model_weight_optuna.get('threshold', 0.5)
        train_pred = (y_train_predProba >= threshold).astype(int)
        train_pred_proba_log_odds = np.log(y_train_predProba / (1 - y_train_predProba + 1e-10))
    else:
        train_pred = current_model.predict(X_train_cv)
        # Utiliser la distance √† l'hyperplan (decision_function) comme proxy pour la probabilit√©
        decision_values = current_model.decision_function(X_train_cv)
        # Normaliser les valeurs de d√©cision pour une approximation de probabilit√©
        y_train_predProba = 1 / (1 + np.exp(-decision_values))
        train_pred_proba_log_odds = decision_values

    train_pred_time = time.time() - start_time_train_pred
    #print(f"Temps de pr√©diction sur entra√Ænement: {train_pred_time:.4f} secondes")

    # Calcul des m√©triques pour l'entra√Ænement
    start_time_train_metrics = time.time()
    tn_train, fp_train, fn_train, tp_train = confusion_matrix(y_train_cv, train_pred).ravel()
    train_metrics_time = time.time() - start_time_train_metrics
    #print(f"Temps de calcul des m√©triques d'entra√Ænement: {train_metrics_time:.4f} secondes")

    # Initialisation des valeurs de PNL
    val_pnl = 0
    train_pnl = 0

    # Calcul du PNL pour les donn√©es de validation
    start_time_val_pnl = time.time()
    if y_pnl_data_val_cv_OrTest is not None:
        # Cr√©er des masques pour les vrais positifs et faux positifs
        tp_mask_val = (y_val_cv == 1) & (val_pred == 1)  # Vrais positifs
        fp_mask_val = (y_val_cv == 0) & (val_pred == 1)  # Faux positifs

        # V√©rification de coh√©rence (optionnelle)
        tp_count = np.sum(tp_mask_val)
        if tp_count != tp_val:
            print(f"Attention: Nombre de TP calcul√© ({tp_count}) diff√©rent de tp_val ({tp_val})")

        fp_count = np.sum(fp_mask_val)
        if fp_count != fp_val:
            print(f"Attention: Nombre de FP calcul√© ({fp_count}) diff√©rent de fp_val ({fp_val})")

        # Calculer PNL total pour validation
        val_pnl = np.sum(y_pnl_data_val_cv_OrTest[tp_mask_val]) + np.sum(y_pnl_data_val_cv_OrTest[fp_mask_val])

        # V√©rification de la coh√©rence entre pr√©dictions et PNL r√©els
        fp_pnls = y_pnl_data_val_cv_OrTest[fp_mask_val]
        positive_fp_pnls = fp_pnls[fp_pnls > 0]

        if len(positive_fp_pnls) > 0:
            print(f"Attention: {len(positive_fp_pnls)} faux positifs ont un PNL > 0, ce qui semble incoh√©rent")
            print(f"Valeurs PNL incoh√©rentes pour les FP: {positive_fp_pnls}")

        tp_pnls = y_pnl_data_val_cv_OrTest[tp_mask_val]
        negative_tp_pnls = tp_pnls[tp_pnls <= 0]

        if len(negative_tp_pnls) > 0:
            print(f"Attention: {len(negative_tp_pnls)} vrais positifs ont un PNL ‚â§ 0, ce qui semble incoh√©rent")
            print(f"Valeurs PNL incoh√©rentes pour les TP: {negative_tp_pnls}")
    val_pnl_time = time.time() - start_time_val_pnl
    #print(f"Temps de calcul du PNL de validation: {val_pnl_time:.4f} secondes")

    # Calcul du PNL pour les donn√©es d'entra√Ænement
    start_time_train_pnl = time.time()
    if y_pnl_data_train_cv is not None:
        # Cr√©er des masques pour les vrais positifs et faux positifs
        tp_mask_train = (y_train_cv == 1) & (train_pred == 1)  # Vrais positifs
        fp_mask_train = (y_train_cv == 0) & (train_pred == 1)  # Faux positifs

        # V√©rification de coh√©rence (optionnelle)
        tp_count = np.sum(tp_mask_train)
        if tp_count != tp_train:
            print(f"Attention: Nombre de TP calcul√© ({tp_count}) diff√©rent de tp_train ({tp_train})")

        fp_count = np.sum(fp_mask_train)
        if fp_count != fp_train:
            print(f"Attention: Nombre de FP calcul√© ({fp_count}) diff√©rent de fp_train ({fp_train})")

        # Calculer PNL total pour entra√Ænement
        train_pnl = np.sum(y_pnl_data_train_cv[tp_mask_train]) + np.sum(y_pnl_data_train_cv[fp_mask_train])

        # V√©rification de la coh√©rence entre pr√©dictions et PNL r√©els pour les donn√©es d'entra√Ænement
        fp_pnls_train = y_pnl_data_train_cv[fp_mask_train]
        positive_fp_pnls_train = fp_pnls_train[fp_pnls_train > 0]

        if len(positive_fp_pnls_train) > 0:
            print(
                f"Attention: {len(positive_fp_pnls_train)} faux positifs dans les donn√©es d'entra√Ænement ont un PNL > 0, ce qui semble incoh√©rent")
            print(f"Valeurs PNL incoh√©rentes pour les FP: {positive_fp_pnls_train}")

        # V√©rifier les vrais positifs (devraient avoir PNL > 0)
        tp_pnls_train = y_pnl_data_train_cv[tp_mask_train]
        negative_tp_pnls_train = tp_pnls_train[tp_pnls_train <= 0]

        if len(negative_tp_pnls_train) > 0:
            print(
                f"Attention: {len(negative_tp_pnls_train)} vrais positifs dans les donn√©es d'entra√Ænement ont un PNL ‚â§ 0, ce qui semble incoh√©rent")
            print(f"Valeurs PNL incoh√©rentes pour les TP: {negative_tp_pnls_train}")
    train_pnl_time = time.time() - start_time_train_pnl
    #print(f"Temps de calcul du PNL d'entra√Ænement: {train_pnl_time:.4f} secondes")

    # Best iteration n'a pas de sens pour SVC, mais on le garde pour la coh√©rence
    best_iteration = None
    best_idx = None

    # üìâ Brier Score brut
    brier = brier_score_loss(y_val_cv, val_pred_proba)

    # üìä Brier Score baseline
    baseline_pred = np.full_like(y_val_cv, y_val_cv.mean(), dtype=np.float64)
    baseline_brier = brier_score_loss(y_val_cv, baseline_pred)
    relative_brier = brier / baseline_brier if baseline_brier > 0 else brier

    # Construction des m√©triques
    start_time_metrics_build = time.time()
    val_metrics = {
        'tp': tp_val,
        'fp': fp_val,
        'tn': tn_val,
        'fn': fn_val,
        'total_samples': len(y_val_cv),
        'val_bestVal_custom_metric_pnl': val_pnl,
        'best_iteration': best_iteration,
        'brier':brier,
        'relative_brier':relative_brier,
    }

    train_metrics = {
        'tp': tp_train,
        'fp': fp_train,
        'tn': tn_train,
        'fn': fn_train,
        'total_samples': len(y_train_cv),
        'train_bestVal_custom_metric_pnl': train_pnl
    }

    # Calculs additionnels pour les statistiques
    tp_fp_tn_fn_sum_val = tp_val + fp_val + tn_val + fn_val
    tp_fp_tn_fn_sum_train = tp_train + fp_train + tn_train + fn_train
    tp_fp_sum_val = tp_val + fp_val
    tp_fp_sum_train = tp_train + fp_train

    train_trades_samples_perct = round(tp_fp_sum_train / tp_fp_tn_fn_sum_train * 100,
                                       2) if tp_fp_tn_fn_sum_train else 0.00
    val_trades_samples_perct = round(tp_fp_sum_val / tp_fp_tn_fn_sum_val * 100, 2) if tp_fp_tn_fn_sum_val else 0.00
    perctDiff_ratioTradeSample_train_val = abs(
        calculate_ratio_difference(train_trades_samples_perct, val_trades_samples_perct, config))
    winrate_train = compute_winrate_safe(tp_train, tp_fp_sum_train, config)
    winrate_val = compute_winrate_safe(tp_val, tp_fp_sum_val, config)
    ratio_difference = abs(calculate_ratio_difference(winrate_train, winrate_val, config))

    # Compilation des statistiques du fold
    fold_stats = compile_fold_stats(
        fold_num, best_iteration, train_pred_proba_log_odds, train_metrics, winrate_train,
        tp_fp_sum_train, tp_fp_tn_fn_sum_train, train_pnl, train_pos, train_trades_samples_perct,
        val_pred_proba_log_odds, val_metrics, winrate_val, tp_fp_sum_val, tp_fp_tn_fn_sum_val,
        val_pnl, val_pos, val_trades_samples_perct, ratio_difference, perctDiff_ratioTradeSample_train_val
    )

    if fold_stats_current is not None:
        fold_stats.update(fold_stats_current)
    metrics_build_time = time.time() - start_time_metrics_build
    #print(f"Temps de construction des m√©triques: {metrics_build_time:.4f} secondes")

    # Mesure du temps total
    total_time = time.time() - start_time_total
    #print(f"Temps total d'ex√©cution de la fonction: {total_time:.4f} secondes")

    # Extraire les vecteurs de support (sp√©cifique √† SVC)
    n_support = current_model.n_support_
    support_vectors_info = {
        'n_support_per_class': n_support,
        'total_support_vectors': sum(n_support),
        'support_vector_ratio': sum(n_support) / len(X_train_cv)
    }

    # Informations de debug avec les temps d'ex√©cution
    debug_info = {
        'model_params': params_optuna,
        #'kernel': params_optuna['svc_kernel'],
        'threshold': model_weight_optuna.get('threshold', 0.5) if svc_probability else None,
        'using_probabilities': svc_probability,
        'support_vectors_info': support_vectors_info,
        'execution_times': {
            'total': total_time,
            'weights_calculation': weights_time,
            'training': train_time,
            'validation_prediction': val_pred_time,
            'validation_metrics': val_metrics_time,
            'training_prediction': train_pred_time,
            'training_metrics': train_metrics_time,
            'validation_pnl': val_pnl_time,
            'training_pnl': train_pnl_time,
            'metrics_building': metrics_build_time
        }
    }

    return {
        'current_model': current_model,
        'y_train_predProba': y_train_predProba,
        'eval_metrics': val_metrics,
        'train_metrics': train_metrics,
        'fold_stats': fold_stats,
        'evals_result': None,
        'best_iteration': best_iteration,
        'val_score_bestIdx': best_idx,
        'debug_info': debug_info,
    }
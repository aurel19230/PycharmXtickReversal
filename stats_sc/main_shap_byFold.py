import streamlit as st
import pandas as pd
import plotly.express as px
import os
from pathlib import Path

# -----------------------------------------------------------------------------
# ğŸ“Œ Configuration gÃ©nÃ©rale
# -----------------------------------------------------------------------------
BASE_HINT = r"C:\Users\aulac\OneDrive\Documents\Trading\PyCharmProject\MLStrategy\data_preprocessing\results_optim"

st.set_page_config(page_title="SHAP Feature Explorer", layout="wide")
st.title("ğŸ“‚ Analyse SHAP â€“ SÃ©lection manuelle + filtres dynamiques")

st.markdown(f"â„¹ï¸ **Conseil :** sÃ©lectionnez un fichier dans : `{BASE_HINT}`")

# -----------------------------------------------------------------------------
# ğŸ“ SÃ©lection du dossier d'export (facultatif)
# -----------------------------------------------------------------------------
custom_output_dir = st.text_input(
    "ğŸ“ Dossier d'exportation personnalisÃ© (laisser vide pour exporter dans le mÃªme dossier)",
    "",
)

# -----------------------------------------------------------------------------
# ğŸ“¥ TÃ©lÃ©versement du fichier CSV de mÃ©triques SHAP
# -----------------------------------------------------------------------------
uploaded_file = st.file_uploader("ğŸ‘‰ Choisissez un fichier CSV SHAP Ã  analyser :", type=["csv"])

if uploaded_file:
    # -------------------------------------------------------------------------
    # ğŸ“Š Lecture du fichier
    # -------------------------------------------------------------------------
    metrics_df = pd.read_csv(uploaded_file, sep=";", index_col=0)
    st.success(f"âœ… Fichier chargÃ© : {uploaded_file.name}")
    st.write(f"Nombre de features chargÃ©es : {metrics_df.shape[0]}")

    # -------------------------------------------------------------------------
    # ğŸ”§ PrÃ©â€‘calculs pour les mÃ©triques dÃ©pendantes des folds
    # -------------------------------------------------------------------------
    shap_fold_cols = [col for col in metrics_df.columns if col.startswith("fold_")]
    nb_folds = len(shap_fold_cols)

    # ğŸ·ï¸ Rank par fold afin de recalculer freq_topN Ã  la volÃ©e (pas besoin de la
    # colonne freq_topN prÃ©sente dans certaines exports)
    # --------------------------------------------------------
    @st.cache_data(hash_funcs={pd.DataFrame: lambda _: None})
    def _compute_rank_df(df: pd.DataFrame) -> pd.DataFrame:
        # Classement dÃ©croissant (plus le SHAP est grand, plus le rang est petit)
        return df.rank(axis=0, method="min", ascending=False)

    rank_df = _compute_rank_df(metrics_df[shap_fold_cols])

    # -------------------------------------------------------------------------
    # ğŸ›ï¸ Filtres de base dans la sidebar
    # -------------------------------------------------------------------------
    st.sidebar.header("ğŸ›ï¸ Filtres SHAP â€“ Vue simplifiÃ©e")

    min_mean = st.sidebar.slider("Seuil minimal de mean_SHAP", 0.0, 0.05, 0.005, step=0.001)
    max_cv = st.sidebar.slider("Seuil maximal de cv_SHAP", 0.0, 1.0, 0.30, step=0.01)
    top_k = st.sidebar.number_input("Limiter Ã  Topâ€‘K features (0 = pas de limite)", 0, 300, 0, step=1)

    use_freq_topN_filter = st.sidebar.checkbox("Filtrer par frÃ©quence dans le Topâ€‘N (simple)")
    if use_freq_topN_filter:
        simple_topN = st.sidebar.slider("N pour freq_topN (Topâ€‘N simple)", 1, 50, 20)
        # Recalcul simple de freq_topN
        freq_topN_simple = (rank_df <= simple_topN).sum(axis=1)
        metrics_df["freq_topN"] = freq_topN_simple  # ğŸ”„ overwrite / crÃ©e
        min_freq_topN_simple = st.sidebar.slider("FrÃ©quence minimale dans le Topâ€‘N", 0, nb_folds, 3)
    else:
        min_freq_topN_simple = None

    # -------------------------------------------------------------------------
    # âš™ï¸ ParamÃ¨tres avancÃ©s â€“ RÃ¨gles parallÃ¨les (BlocÂ A et BlocÂ B)
    # -------------------------------------------------------------------------
    st.sidebar.subheader("âš™ï¸ ParamÃ¨tres avancÃ©s (BlocÂ A & BlocÂ B)")

    # ğŸ”¹ ParamÃ¨tres pour le calcul de freq_topN avancÃ©
    adv_topN = st.sidebar.slider("N (Topâ€‘N par fold) pour freq_topN avancÃ©", 1, 50, 20)
    # Recalcul avancÃ© de freq_topN (peut Ãªtre diffÃ©rent du simple)
    metrics_df["freq_topN_adv"] = (rank_df <= adv_topN).sum(axis=1)

    # ğŸ”¹ Seuils BlocÂ A
    min_freq_topN_A = st.sidebar.slider("BlocÂ AÂ : FrÃ©quence minimale dans le Topâ€‘N", 0, nb_folds, 2)
    max_cv_A = st.sidebar.slider("BlocÂ AÂ : Seuil maximal de cv_SHAP", 0.0, 1.0, 0.5, step=0.01)

    # ğŸ”¹ Seuils BlocÂ B
    min_mean_B = st.sidebar.slider("BlocÂ BÂ : Seuil minimal de mean_SHAP", 0.0, 0.05, 0.002, step=0.001)
    min_freq_nonzero_B = st.sidebar.slider("BlocÂ BÂ : FrÃ©quence minimale nonâ€‘zÃ©ro", 0, nb_folds, 2)

    # -------------------------------------------------------------------------
    # ğŸ§® Calcul des mÃ©triques dÃ©rivÃ©es (freq_nonzero)
    # -------------------------------------------------------------------------
    if "freq_nonzero" not in metrics_df.columns:
        metrics_df["freq_nonzero"] = (metrics_df[shap_fold_cols] != 0).sum(axis=1)

    # -------------------------------------------------------------------------
    # ğŸ—‚ï¸ Application des filtres de base (kept)
    # -------------------------------------------------------------------------
    metrics_df["kept"] = (
        (metrics_df["mean_SHAP"] >= min_mean) & (metrics_df["cv_SHAP"] <= max_cv)
    )
    if min_freq_topN_simple is not None:
        metrics_df["kept"] &= (metrics_df["freq_topN"] >= min_freq_topN_simple)

    # -------------------------------------------------------------------------
    # ğŸ” RÃ¨gles parallÃ¨les avancÃ©es (BlocÂ A & BlocÂ B)
    # -------------------------------------------------------------------------
    mask_A = (
        (metrics_df["freq_topN_adv"] >= min_freq_topN_A)
        & (metrics_df["cv_SHAP"] <= max_cv_A)
    )
    mask_B = (
        (metrics_df["mean_SHAP"] >= min_mean_B)
        & (metrics_df["freq_nonzero"] >= min_freq_nonzero_B)
    )

    combined_mask = mask_A | mask_B
    nb_total_combined = int(combined_mask.sum())
    features_combined = metrics_df.index[combined_mask].tolist()

    # -------------------------------------------------------------------------
    # ğŸ–¨ï¸ Logs console
    # -------------------------------------------------------------------------
    print(
        f"ğŸ” BlocÂ A (TopN â‰¥ {min_freq_topN_A} & cv_SHAP â‰¤ {max_cv_A}) : {mask_A.sum()} features"
    )
    print(
        f"ğŸ” BlocÂ B (mean_SHAP â‰¥ {min_mean_B} & freq_nonzero â‰¥ {min_freq_nonzero_B}) : {mask_B.sum()} features"
    )
    print(f"âœ… Total combinÃ© (A âˆª B) : {nb_total_combined} features")
    for feat in features_combined:
        print(f"  - {feat}")

    # -------------------------------------------------------------------------
    # ğŸ–¼ï¸ Interface Streamlit â€“ RÃ©capitulatif Bloc A / Bloc B
    # -------------------------------------------------------------------------
    st.markdown("### ğŸ” AperÃ§u des rÃ¨gles de filtrage avancÃ©es (parallÃ¨le)")
    summary_text = (
        f"BlocÂ A (TopN â‰¥ {min_freq_topN_A} & cv_SHAP â‰¤ {max_cv_A}) : {mask_A.sum()} features\n"
        f"BlocÂ B (mean_SHAP â‰¥ {min_mean_B} & freq_nonzero â‰¥ {min_freq_nonzero_B}) : {mask_B.sum()} features\n"
        f"Total combinÃ© retenu par A ou B : {nb_total_combined} features"
    )
    st.code(summary_text, language="markdown")

    st.text_area(
        label="ğŸ§  Features retenues (rÃ¨gle A âˆª B)",
        value="\n".join(features_combined),
        height=200,
    )

    # -------------------------------------------------------------------------
    # ğŸ“‹ Affichage des features retenues par le filtrage principal
    # -------------------------------------------------------------------------
    filtered = metrics_df[metrics_df["kept"]].copy()
    if top_k > 0:
        filtered = filtered.sort_values("mean_SHAP", ascending=False).head(top_k)

    st.subheader(f"ğŸ“Š {len(filtered)} features retenues aprÃ¨s filtrage de base")
    st.dataframe(filtered.sort_values("mean_SHAP", ascending=False))

    fig = px.scatter(
        metrics_df,
        x="mean_SHAP",
        y="cv_SHAP",
        color="kept",
        hover_name=metrics_df.index,
        size="freq_topN_adv",
        title="SHAP importance vs StabilitÃ©",
    )
    st.plotly_chart(fig, use_container_width=True)

    # -------------------------------------------------------------------------
    # ğŸ’¾ Export CSV
    # -------------------------------------------------------------------------
    if st.button("ğŸ’¾ Exporter les features filtrÃ©es"):
        export_name = f"filtered_{uploaded_file.name}"

        # Log features filtrÃ©es
        print(f"âœ… {len(filtered)} features retenues (filtrage standard):")
        for f in filtered.index.tolist():
            print(f"  - {f}")

        if custom_output_dir and os.path.isdir(custom_output_dir):
            export_path = os.path.join(custom_output_dir, export_name)
            try:
                filtered.to_csv(export_path, sep=";")
                st.success(f"âœ… ExportÃ© avec succÃ¨s dans : `{export_path}`")
            except Exception as e:
                st.error(f"âŒ Erreur lors de l'export : {str(e)}")
                st.download_button(
                    label="ğŸ“¥ TÃ©lÃ©charger le fichier CSV filtrÃ©",
                    data=filtered.to_csv(sep=";").encode("utf-8"),
                    file_name=export_name,
                    mime="text/csv",
                )
        else:
            st.download_button(
                label="ğŸ“¥ TÃ©lÃ©charger le fichier CSV filtrÃ©",
                data=filtered.to_csv(sep=";").encode("utf-8"),
                file_name=export_name,
                mime="text/csv",
            )
            if custom_output_dir:
                st.warning(f"âš ï¸ Le dossier `{custom_output_dir}` est invalide.")
else:
    st.info(f"Veuillez tÃ©lÃ©verser un fichier CSV Ã  partir de `{BASE_HINT}` ou ailleurs.")

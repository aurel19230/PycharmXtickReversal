import numpy as np
import pandas as pd
import os
import matplotlib.pyplot as plt
import seaborn as sns
import scipy.stats as stats
from statsmodels.stats.power import TTestIndPower
from sklearn.feature_selection import f_classif  # Test F (ANOVA)
from definition import load_data
# D√©finir l'option pour afficher toutes les colonnes
pd.set_option('display.max_columns', None)
from standard_stat_sc import *

# Si vous voulez √©galement afficher toutes les lignes
pd.set_option('display.max_rows', None)

# Pour afficher plus de caract√®res dans chaque colonne (√©viter la troncation des valeurs)
pd.set_option('display.width', 1000)  # Ajustez ce nombre selon vos besoins


# Chemin vers ton fichier
file_name = "Step5_5_0_5TP_1SL_150924_280225_bugFixTradeResult_extractOnlyFullSession_OnlyShort_feat_winsorized.csv"
directory_path = "C:\\Users\\aulac\\OneDrive\\Documents\\Trading\\VisualStudioProject\\Sierra chart\\xTickReversal\\simu\\5_0_5TP_1SL\\\merge_I1_I2"
file_path = os.path.join(directory_path, file_name)

# Charger les donn√©es
df = load_data(file_path)


# ---- FONCTION D'ANALYSE AVEC TEST F (ANOVA) ---- #
import numpy as np
import pandas as pd
from scipy import stats
from statsmodels.stats.power import TTestIndPower
from sklearn.feature_selection import f_classif
import numpy as np
import pandas as pd
from scipy import stats
from statsmodels.stats.power import TTestIndPower
import time
from datetime import timedelta

import numpy as np
import pandas as pd
from scipy import stats
from statsmodels.stats.power import TTestIndPower
from stats_sc.standard_stat_sc import calculate_statistical_power,calculate_statistical_power_job


# ---- CHARGEMENT DES FEATURES √Ä ANALYSER ---- #

if True:
    feature_list = [
        'ratio_volRevMove_volImpulsMove',
        'ratio_deltaZone1_volZone1',
        'ratio_deltaExtrem_volExtrem',
        'ratio_volRevMoveZone1_volImpulsMoveExtrem_XRevZone',
        'ratio_deltaRevMoveZone1_volRevMoveZone1',
        'ratio_deltaRevMoveExtrem_volRevMoveExtrem',
        'ratio_deltaRevMove_volRevMove',
       # '',
    ]
else:
    # Colonnes √† exclure explicitement (variables cibles, pnl, dates...)
    excluded_columns = [
        'class_binaire',
        'timestamp',
        'SessionStartEnd',
        'trade_pnl_theoric', 'trade_pnl', 'trade_category','sl_pnl',
        'tp3_pnl', 'tp2_pnl', 'tp1_pnl', 'tp1_pnl_theoric',
        'timeStampOpening', 'date', 'close', 'high', 'low', 'open'
    ]

    # ‚úÖ S√©lection correcte des colonnes num√©riques en excluant explicitement celles mentionn√©es
    feature_list = df.select_dtypes(include=[np.number]).columns.difference(excluded_columns).tolist()

# V√©rification
print(f"üìå Nombre de features s√©lectionn√©es : {len(feature_list)}")
print(f"üîπ Liste des features :\n{feature_list}")

# Filtrage des donn√©es (classe binaire doit √™tre 0 ou 1)
df_filtered = df[df['class_binaire'].isin([0, 1])]

# ---- EXPLICATION DES R√âSULTATS ---- #
explanation = """
üîç **Explication des variables du tableau de r√©sultats :**

- **Feature** : Nom de la feature analys√©e.
- **Sample_Size** : Nombre d'observations utilis√©es apr√®s filtrage des NaN.
- **Effect_Size (Cohen's d)** : Mesure de la s√©paration entre les deux classes.
  - **> 0.8** : Effet fort ‚úÖ
  - **0.5 - 0.8** : Effet moyen ‚ö†Ô∏è
  - **< 0.5** : Effet faible ‚ùå

- **P-Value** : Probabilit√© d'observer la relation par hasard.
  - **< 0.01** : Tr√®s significatif ‚úÖ‚úÖ
  - **0.01 - 0.05** : Significatif ‚úÖ
  - **0.05 - 0.10** : Marginalement significatif ‚ö†Ô∏è
  - **> 0.10** : Non significatif ‚ùå

- **Fisher_Score (ANOVA F-test)** : Mesure la force discriminante de la feature.
  - **> 20** : Exceptionnellement puissant ‚úÖ‚úÖ
  - **10 - 20** : Tr√®s int√©ressant ‚úÖ
  - **5 - 10** : Mod√©r√©ment int√©ressant ‚ö†Ô∏è
  - **1 - 5** : Faiblement int√©ressant ‚ùå
  - Dans le trading, m√™me des scores modestes peuvent avoir une valeur s'ils sont stables dans le temps.

- **Power_Analytical** : Puissance statistique bas√©e sur une formule analytique.
- **Power_MonteCarlo** : Puissance statistique estim√©e via simulations.
- **Required_N** : Nombre d'observations n√©cessaires pour atteindre **Puissance = 0.8**.
- **Power_Sufficient** : L'√©chantillon actuel est-il suffisant pour garantir la fiabilit√© de l'effet observ√© ?

üéØ **Interpr√©tation des seuils de puissance statistique** :
- ‚úÖ **Puissance ‚â• 0.8** : La feature a une distinction nette entre classes. R√©sultat tr√®s fiable.
- ‚ö†Ô∏è **0.6 ‚â§ Puissance < 0.8** : Impact potentiel, mais fiabilit√© mod√©r√©e. √Ä consid√©rer dans un ensemble de signaux.
- ‚ùå **Puissance < 0.6** : Fiabilit√© insuffisante. Risque √©lev√© que la relation observ√©e soit due au hasard.

üìà **Consid√©rations sp√©cifiques pour le trading** :
- Une feature avec un Fisher Score modeste mais stable sur diff√©rentes p√©riodes peut √™tre plus pr√©cieuse qu'une feature avec un score √©lev√© mais instable.
- Surveillez la compl√©mentarit√© des features : des variables individuellement modestes peuvent cr√©er un signal puissant en combinaison.
- V√©rifiez toujours la robustesse apr√®s prise en compte des frais de transaction.
- Pour les strat√©gies haute fr√©quence, m√™me des effets faibles peuvent √™tre exploitables si la significativit√© statistique est forte.
"""

print(explanation)

# ---- ANALYSE DE PUISSANCE ---- #
print("\nüîç **Analyse de puissance statistique pour les features :**")
# Pr√©paration des donn√©es
# Pr√©paration des donn√©es
X = df_filtered[feature_list].copy()  # DataFrame contenant uniquement les features s√©lectionn√©es
y = df_filtered['class_binaire'].copy()  # S√©rie de la cible

# Exemple d'utilisation:
results = correlation_matrices(X, y)
#
# # Pour acc√©der aux r√©sultats:
# pearson_matrix = results['pearson_matrix']
# spearman_target = results['spearman_target']

# Appel de la fonction avec X pr√©-filtr√©

power_results = calculate_statistical_power(X, y,target_power=0.8, n_simulations_monte=20000,
                                sample_fraction=0.8, verbose=True,
                                method_powerAnaly='both')              # S√©rie de la cible



# Utilisez les r√©sultats comme avant
powerful_features = power_results[power_results['Power_MonteCarlo'] >= 0.5]['Feature'].tolist()
print(f"\n‚úÖ **Features avec une puissance suffisante (‚â• 0.5) :** {len(powerful_features)}/{len(feature_list)}")
print(power_results)

# ---- VISUALISATION ---- #
def plot_power_analysis(power_results):
    if power_results.empty:
        print("Pas de r√©sultats d'analyse de puissance √† visualiser.")
        return

    fig, ax1 = plt.subplots(figsize=(12, 6))

    sns.barplot(x='Feature', y='Power_MonteCarlo', data=power_results, ax=ax1, palette='viridis')
    ax1.axhline(y=0.8, color='r', linestyle='--', label='Puissance cible = 0.8')
    ax1.set_title('Puissance statistique par feature (Monte Carlo)')
    ax1.set_xticklabels(ax1.get_xticklabels(), rotation=90)
    ax1.set_ylabel('Puissance')
    ax1.legend()
    plt.show()

# ---- FILTRAGE DES FEATURES PERTINENTES ---- #
powerful_features = power_results[power_results['Power_MonteCarlo'] >= 0.5]['Feature'].tolist()
print(f"\n‚úÖ **Features avec une puissance suffisante (‚â• 0.6) :** {len(powerful_features)}/{len(feature_list)}")
if powerful_features:
    print("\n".join(f"- {f}" for f in powerful_features))
plot_power_analysis(power_results)



print("\n\nCode pour les disctribution dans le code suive cette partie")

def plot_feature_distributions(df, feature_list, target_col='class_binaire', figsize=(16, 10)):
    from sklearn.feature_selection import f_classif
    from matplotlib.patches import Patch
    import numpy as np
    import pandas as pd
    import matplotlib.pyplot as plt
    import seaborn as sns
    from matplotlib.gridspec import GridSpec
    import warnings

    n_features = len(feature_list)
    n_cols = 2
    n_rows = int(np.ceil(n_features / n_cols))

    # Cr√©ation d'une figure avec GridSpec pour mieux contr√¥ler les sous-graphiques
    fig = plt.figure(figsize=figsize)

    # Cr√©ation d'un GridSpec avec une ligne suppl√©mentaire pour la l√©gende
    gs = GridSpec(n_rows + 1, n_cols, figure=fig, height_ratios=[*[1] * n_rows, 0.1])

    fig.suptitle('Distribution des features par classe', fontsize=16)

    sns.set_style("whitegrid")
    palette = {0: "royalblue", 1: "crimson"}

    axes = []
    for i in range(n_rows):
        for j in range(n_cols):
            if i * n_cols + j < n_features:
                # Ajouter les axes pour chaque graphique
                axes.append(fig.add_subplot(gs[i, j]))

    for i, feature in enumerate(feature_list):
        if i < len(axes):
            ax = axes[i]

            if feature in df.columns:
                # Ne pas afficher la l√©gende pour chaque graphique
                sns.histplot(
                    data=df,
                    x=feature,
                    hue=target_col,
                    kde=True,
                    palette=palette,
                    alpha=0.6,
                    ax=ax,
                    legend=False  # Suppression de la l√©gende individuelle
                )

                # Calculer les statistiques pour chaque classe
                class0 = df[df[target_col] == 0][feature]
                class1 = df[df[target_col] == 1][feature]

                # V√©rifier s'il y a des valeurs dans chaque classe
                if len(class0) > 0 and len(class1) > 0:
                    # Calculer les moyennes et √©carts-types en ignorant les NaN
                    mean0, std0 = class0.mean(skipna=True), class0.std(skipna=True)
                    mean1, std1 = class1.mean(skipna=True), class1.std(skipna=True)

                    # V√©rifier si les valeurs sont valides (non NaN)
                    mean0 = mean0 if pd.notna(mean0) else 0
                    std0 = std0 if pd.notna(std0) else 0
                    mean1 = mean1 if pd.notna(mean1) else 0
                    std1 = std1 if pd.notna(std1) else 0

                    # Gestion des NaN pour f_classif
                    X = df[[feature]].copy()
                    y = df[target_col].copy()

                    # Filtrer les lignes sans NaN (pour les deux X et y)
                    mask = X[feature].notna() & y.notna()
                    X_filtered = X.loc[mask]
                    y_filtered = y.loc[mask]

                    # Calculer f_classif seulement s'il y a assez de donn√©es
                    if len(X_filtered) > 0 and len(np.unique(y_filtered)) > 1:
                        try:
                            with warnings.catch_warnings():
                                warnings.simplefilter("ignore")
                                f_scores, p_values = f_classif(X_filtered, y_filtered)
                                f_stat, p_val = f_scores[0], p_values[0]
                        except Exception as e:
                            print(f"Erreur lors du calcul f_classif pour {feature}: {e}")
                            f_stat, p_val = 0, 1
                    else:
                        f_stat, p_val = 0, 1

                    # Ajustement de l'annotation avec des valeurs s√©curis√©es
                    ax.annotate(
                        f"Cl.0: ¬µ={mean0:.2f}, œÉ={std0:.2f}\n"
                        f"Cl.1: ¬µ={mean1:.2f}, œÉ={std1:.2f}\n"
                        f"F: {f_stat:.2f}, p: {p_val:.3f}",
                        xy=(0.98, 0.95),
                        xycoords='axes fraction',
                        ha='right',
                        va='top',
                        fontsize='small',
                        bbox=dict(boxstyle="round,pad=0.2", fc="white", alpha=0.8)
                    )

                ax.set_title(f"{feature}", fontsize=12)
                ax.set_xlabel(feature, fontsize=10)
                ax.set_ylabel("Fr√©quence", fontsize=10)
            else:
                ax.text(0.5, 0.5, f"{feature} non trouv√©e",
                        ha='center', va='center', fontsize=10)
                ax.set_axis_off()

    # Cr√©ation d'un subplot d√©di√© pour la l√©gende
    legend_ax = fig.add_subplot(gs[n_rows, :])
    legend_ax.axis('off')  # Masquer les axes

    # Cr√©ation des handles pour la l√©gende
    legend_handles = [
        Patch(facecolor="royalblue", edgecolor="black", label="Classe 0"),
        Patch(facecolor="crimson", edgecolor="black", label="Classe 1")
    ]

    # Ajout de la l√©gende au subplot d√©di√©
    legend = legend_ax.legend(
        handles=legend_handles,
        title='Classes',
        loc='center',
        ncol=2,
        fontsize='medium',
        framealpha=0.8
    )

    plt.tight_layout()
    plt.show()

    return fig

# V√©rifier que le filtrage a fonctionn√©
#print(df_filtered['class_binaire'].unique())

# Utiliser le DataFrame filtr√©
plot_feature_distributions(df_filtered, feature_list)